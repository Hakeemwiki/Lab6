# Option 1: Use official Spark base image
FROM apache/spark-py

# Switch to root for installations
USER root

# Install additional dependencies
RUN apt-get update && apt-get install -y \
    curl \
    procps \
    && apt-get clean && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy transformation script
COPY src/transformation/transform.py .

# Set environment variables
ENV SPARK_LOCAL_IP=127.0.0.1

# Switch back to default user (if applicable, adjust based on base image)
# USER ${SPARK_USER:-spark}  # Uncomment and adjust if needed

# Command to run the script
ENTRYPOINT ["python", "transform.py"]